{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575c11d4",
   "metadata": {},
   "source": [
    "# Creating Naive Bayes Models for Sentiment Analysis using Valheim Twitter Dataset\n",
    "\n",
    "From the previous project (Sentiment Analysis of Valheim (Video Game) based on Twitter Dataset using Keras BiLSTM), I will reuse the same dataset and create 3 sentiment analysis models using Naive Bayes algorithm. The models are Multinomial Naive Bayes, Complement Naive Bayes, and Bernoulli Naive Bayes. The models will be evaluated twice, first when they're fitted only once with 70:30 split, and second when they're fitted 10 times using k-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a693a0c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8f9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a459abde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElPibeCombo</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>@BS_artsss Oh, this is so good, i love it! can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MrsTadertaut</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>5</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Hello lovelies!\\n\\nTonight we are jumping back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meganoip</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Storyline: Noi found Block fighting with giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TaesTeahouse</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Ayo I'm totally not biased or anything but yal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John90192410</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>The Queen Wants it all... \\nDid Mistlands solo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User Date Created  Number of Likes      Source of Tweet  \\\n",
       "0   ElPibeCombo   2022-12-15                0      Twitter Web App   \n",
       "1  MrsTadertaut   2022-12-15                5      Twitter Web App   \n",
       "2      Meganoip   2022-12-15                0      Twitter Web App   \n",
       "3  TaesTeahouse   2022-12-15                2      Twitter Web App   \n",
       "4  John90192410   2022-12-15                1  Twitter for Android   \n",
       "\n",
       "                                               Tweet  \n",
       "0  @BS_artsss Oh, this is so good, i love it! can...  \n",
       "1  Hello lovelies!\\n\\nTonight we are jumping back...  \n",
       "2  Storyline: Noi found Block fighting with giant...  \n",
       "3  Ayo I'm totally not biased or anything but yal...  \n",
       "4  The Queen Wants it all... \\nDid Mistlands solo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('scrapped_tweet.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aa5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = (df[\"Tweet\"].values.tolist())\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "contractions.add('cant', 'can not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432baaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh good love wait get home play valheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello loveliestonight jumping back made copper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storyline noi found block fighting giant valhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayo totally biased anything go watch lil si pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen want mistlands solo cheating died time b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0            oh good love wait get home play valheim\n",
       "1  hello loveliestonight jumping back made copper...\n",
       "2  storyline noi found block fighting giant valhe...\n",
       "3  ayo totally biased anything go watch lil si pl...\n",
       "4  queen want mistlands solo cheating died time b..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanTweet(arr):\n",
    "    #Create a new list to store the cleaned tweets\n",
    "    clean_tweet = []\n",
    "    for i in range(0,len(arr)):\n",
    "        #Undercase all letters\n",
    "        temp = p.clean(arr[i]).casefold()\n",
    "        #Remove all punctuations\n",
    "        temp = temp.translate(str.maketrans('', '', string.punctuation))\n",
    "        #Create new list to store filtered tokenized words\n",
    "        filtered = []\n",
    "        #Create new variable for tokenized sentence\n",
    "        words_temp = word_tokenize(temp)\n",
    "        #Create new variable to store string that has its contractions removed\n",
    "        str_temp_fixed = \"\"\n",
    "        #Clean the words from contractions\n",
    "        for j in words_temp:\n",
    "            j = contractions.fix(j)\n",
    "            str_temp_fixed += \" \" + j\n",
    "        #Create new variable for the cleaned tokenized sentence\n",
    "        words_temp_fixed = word_tokenize(str_temp_fixed)\n",
    "        for c in words_temp_fixed:\n",
    "            #Check if a word is a stop word\n",
    "            if c not in stop_words:\n",
    "                #Lemmatize the word, then stores it into the \"filtered\" list\n",
    "                c = wordnet_lemmatizer.lemmatize(c)\n",
    "                filtered.append(c)\n",
    "        #Create a new variable to store the filtered words that are re-combined back into a sentence\n",
    "        cleaned = \" \".join(filtered)\n",
    "        #Insert the \"cleaned\" variable to \"clean_tweet\" list\n",
    "        clean_tweet.append(cleaned)\n",
    "        \n",
    "    return clean_tweet\n",
    "    \n",
    "cleaned = pd.DataFrame(cleanTweet(tweet), columns=[\"Tweet\"])\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c1e3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "#Take 20 top words\n",
    "a =  ' '.join(map(str, cleaned[\"Tweet\"]))\n",
    "counted = {k: v for k, v in sorted(word_count(a).items(), key=lambda item: item[1], reverse=True)}\n",
    "counted = dict(Counter(counted).most_common(15))\n",
    "\n",
    "plt.barh(range(len(counted)), list(counted.values()), align='center')\n",
    "plt.yticks(range(len(counted)), list(counted.keys()))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f6d4c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh good love wait home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello loveliestonight jumping back made copper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storyline noi found block fighting giant drago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayo totally biased anything go watch lil si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen want solo cheating died biome felt impos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0                             oh good love wait home\n",
       "1  hello loveliestonight jumping back made copper...\n",
       "2  storyline noi found block fighting giant drago...\n",
       "3        ayo totally biased anything go watch lil si\n",
       "4  queen want solo cheating died biome felt impos..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_stop = ['valheim', 'mistlands', 'new', 'game', 'live', \n",
    "               'update', 'playing', 'time', 'play', 'get', 'stream', \n",
    "               'u', 'going', 'server', 'am', 'pm', 'est', 'tonight', 'today', 'tomorrow', 'yesterday']\n",
    "\n",
    "#Create a new list to store the cleaned tweets\n",
    "def manual_tweetClean(arr):\n",
    "    manual_clean_tweet = []\n",
    "    for i in range(0,len(tweet)):\n",
    "        temp = arr.iloc[i]\n",
    "        #Create new list to store filtered tokenized words\n",
    "        filtered = []\n",
    "        #Create new variable for tokenized sentence\n",
    "        words_temp = word_tokenize(temp)\n",
    "        for c in words_temp:\n",
    "            #Check if a word is a stop word\n",
    "            if c not in manual_stop:\n",
    "                #Stores it into the \"filtered\" list\n",
    "                filtered.append(c)\n",
    "        #Create a new variable to store the filtered words that are re-combined back into a sentence\n",
    "        cleaned = \" \".join(filtered)\n",
    "        #Insert the \"cleaned\" variable to \"manual_clean_tweet\" list\n",
    "        manual_clean_tweet.append(cleaned)\n",
    "    return manual_clean_tweet\n",
    "\n",
    "#Create a new dataframe filled with the cleaned tweets\n",
    "cleaned[\"Tweet\"] = manual_tweetClean(cleaned[\"Tweet\"])\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54baec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh good love wait home</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello loveliestonight jumping back made copper...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storyline noi found block fighting giant drago...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>-0.7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayo totally biased anything go watch lil si</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.3384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen want solo cheating died biome felt impos...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.8360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Positive  Neutral  \\\n",
       "0                             oh good love wait home     0.703    0.297   \n",
       "1  hello loveliestonight jumping back made copper...     0.000    1.000   \n",
       "2  storyline noi found block fighting giant drago...     0.000    0.772   \n",
       "3        ayo totally biased anything go watch lil si     0.000    0.745   \n",
       "4  queen want solo cheating died biome felt impos...     0.188    0.348   \n",
       "\n",
       "   Compound  \n",
       "0    0.7964  \n",
       "1    0.0000  \n",
       "2   -0.7717  \n",
       "3   -0.3384  \n",
       "4   -0.8360  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add new columns to the dataframe for the result of the analyzer\n",
    "\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "cleaned[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in cleaned[\"Tweet\"]]\n",
    "cleaned[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in cleaned[\"Tweet\"]]\n",
    "cleaned['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in cleaned[\"Tweet\"]]\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d94bf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh good love wait home</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello loveliestonight jumping back made copper...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storyline noi found block fighting giant drago...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>-0.7717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayo totally biased anything go watch lil si</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.3384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen want solo cheating died biome felt impos...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.8360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Positive  Neutral  \\\n",
       "0                             oh good love wait home     0.703    0.297   \n",
       "1  hello loveliestonight jumping back made copper...     0.000    1.000   \n",
       "2  storyline noi found block fighting giant drago...     0.000    0.772   \n",
       "3        ayo totally biased anything go watch lil si     0.000    0.745   \n",
       "4  queen want solo cheating died biome felt impos...     0.188    0.348   \n",
       "\n",
       "   Compound  Sentiment  \n",
       "0    0.7964          1  \n",
       "1    0.0000          0  \n",
       "2   -0.7717          0  \n",
       "3   -0.3384          0  \n",
       "4   -0.8360          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column in the dataframe to store the sentiment of each tweets using Compound value\n",
    "\n",
    "score = cleaned[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i > 0 :\n",
    "        sentiment.append(1)\n",
    "    else:\n",
    "        sentiment.append(0)\n",
    "cleaned[\"Sentiment\"] = sentiment\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d16cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(ngram_range=(1,1), tokenizer=token.tokenize)\n",
    "textcount = cv.fit_transform(cleaned[\"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80b0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = textcount\n",
    "y = cleaned[\"Sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91844525",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4833f120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, y_train)\n",
    "\n",
    "CNB = ComplementNB()\n",
    "CNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e27b9a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes: 80.87%\n",
      "Accuracy of Bernoulli Naive Bayes: 77.07%\n",
      "Accuracy of Complement Naive Bayes: 79.67%\n"
     ]
    }
   ],
   "source": [
    "y_pred = MNB.predict(X_test)\n",
    "print(\"Accuracy of Multinomial Naive Bayes: {:.2f}%\".format(metrics.accuracy_score(y_pred, y_test)*100))\n",
    "\n",
    "y_pred = BNB.predict(X_test)\n",
    "print(\"Accuracy of Bernoulli Naive Bayes: {:.2f}%\".format(metrics.accuracy_score(y_pred, y_test)*100))\n",
    "\n",
    "y_pred = CNB.predict(X_test)\n",
    "print(\"Accuracy of Complement Naive Bayes: {:.2f}%\".format(metrics.accuracy_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46f297",
   "metadata": {},
   "source": [
    "From this result, it shows that Multinomial Naive Bayes is the best algorithm with the most accuracy of 80.87%, just slightly above Complement Naive Bayes with 79.67% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d7de8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes 10 k-folds: 81.02%\n",
      "Accuracy of Bernoulli Naive Bayes 10 k-folds: 78.68%\n",
      "Accuracy of Complement Naive Bayes 10 k-folds: 79.98%\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "cvMNB = cross_validate(MNB, X, y, cv=10)\n",
    "print(\"Accuracy of Multinomial Naive Bayes 10 k-folds: {:.2f}%\".format(cvMNB['test_score'].mean()*100))\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "cvBNB = cross_validate(BNB, X, y, cv=10)\n",
    "print(\"Accuracy of Bernoulli Naive Bayes 10 k-folds: {:.2f}%\".format(cvBNB['test_score'].mean()*100))\n",
    "\n",
    "CNB = ComplementNB()\n",
    "cvCNB = cross_validate(CNB, X, y, cv=10)\n",
    "print(\"Accuracy of Complement Naive Bayes 10 k-folds: {:.2f}%\".format(cvCNB['test_score'].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78800494",
   "metadata": {},
   "source": [
    "After the 10 k-fold cross validation, Multinomial Naive Bayes still is the best algorithm with average accuracy of 81.02%, just slightly above Complement Naive Bayes with average accuracy of 79.98%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
